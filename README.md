# üß† Multimodal RAG (Gemini + FAISS)

A **real working multimodal Retrieval-Augmented Generation (RAG)** system that ingests PDFs, DOCX files, text/markdown, **images (OCR)**, and **YouTube transcripts**, converts them into semantic embeddings using **Sentence Transformers**, indexes them into **FAISS**, and performs **LLM-grounded answering** using **Google Gemini (Free API)**.

This project is built to demonstrate a **production-style pipeline** while remaining **lightweight and fully local** for indexing & retrieval. Gemini is used only for the final reasoning/answering step.

---

## ‚úÖ Key Features

| Capability | Status |
|-----------|--------|
| PDF ingestion (real) | ‚úÖ |
| Image OCR (pytesseract) | ‚úÖ |
| DOCX, MD, TXT support | ‚úÖ |
| YouTube transcript fetch | ‚úÖ |
| Semantic chunking | ‚úÖ |
| Embeddings via SBERT | ‚úÖ |
| FAISS vector index | ‚úÖ |
| Gemini 1.5 Flash for final answer | ‚úÖ |
| Mac (Apple Silicon) setup tested | ‚úÖ |

---

## üîé Architecture (End-to-End)

```mermaid
flowchart LR
    A[Upload PDF/Image/Docx/YouTube URL] --> B[Extract Text (pdfminer/pytesseract/YT captions)]
    B --> C[Chunking (450 tokens with overlap)]
    C --> D[Embed using Sentence Transformers]
    D --> E[FAISS Vector Store (Inner Product)]
    E -->|Top-k retrieved chunks| F[Gemini 1.5 Flash]
    F --> G[Grounded Final Answer + Citations]
````

---

## üõ† Tech Stack

| Layer                | Tech                                     |
| -------------------- | ---------------------------------------- |
| LLM                  | Gemini 1.5 Flash (Free Tier)             |
| Vector DB            | FAISS (CPU)                              |
| Embeddings           | `sentence-transformers/all-MiniLM-L6-v2` |
| OCR                  | Tesseract (Apple Silicon)                |
| PDF parsing          | pdfminer.six                             |
| Transcript ingestion | youtube-transcript-api                   |
| API backend          | FastAPI                                  |
| UI                   | Auto-served HTML (no Streamlit)          |

---

## ‚úÖ Mac (Apple Silicon / M1/M2/M3/M4) Setup

### 1Ô∏è‚É£ Install Tesseract (for OCR)

```bash
brew install tesseract
```

### 2Ô∏è‚É£ Create a venv (recommended)

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3Ô∏è‚É£ Install Python deps

```bash
pip install fastapi uvicorn[standard] google-generativeai \
    sentence-transformers faiss-cpu pdfminer.six pytesseract \
    python-docx youtube-transcript-api pillow
```

### 4Ô∏è‚É£ Export Gemini API key

```bash
export GEMINI_API_KEY="YOUR_KEY_HERE"
```

### 5Ô∏è‚É£ Run the server

```bash
uvicorn app:app --reload
```

Then visit:

```
http://localhost:8000/
```

---

## üì∏ Screenshots

### 1) Upload & Ingest  
![Upload](./screenshots/upload.png)

### 2) Ingestion Pipeline  
![Ingestion](./screenshots/ingestion.png)

### 3) Top-k Retrieval  
![Retrieval](./screenshots/retrieval.png)

### 4) Grounded Gemini Answer  
![Answer](./screenshots/answer.png)


---

## üî¨ Why RAG instead of vanilla LLM?

| Problem        | Pure LLM            | With RAG                    |
| -------------- | ------------------- | --------------------------- |
| Data freshness | ‚ùå hallucinations    | ‚úÖ grounded in uploaded docs |
| Citations      | ‚ùå no traceability   | ‚úÖ chunk-level evidence      |
| Domain files   | ‚ùå forgotten context | ‚úÖ FAISS vector search       |
| Multimedia     | ‚ùå text-only         | ‚úÖ OCR + transcripts         |

---

## üìå Future Work (Upgrade Path)

| Next Step        | Upgrade                             |
| ---------------- | ----------------------------------- |
| Audio/Video      | Add Whisper / Gemini audio pipeline |
| Vision reasoning | Gemini Vision ‚Üí chunk alignment     |
| Cloud            | GCS storage + remote vector DB      |
| Auth             | JWT + role-based retrieval access   |

---

## üìÑ License

MIT License ‚Äî You are free to extend and publish this system.

---

